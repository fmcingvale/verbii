\ Benchmarking suite
\
\ Copyright (c) 2022 Frank McIngvale, see LICENSE

\ small, medium or large
\
\ test cases are sized by these criteria:
\	small: runs under Python port in ~30 seconds
\	medium: runs under Lua port in ~30 seconds
\	large: runs under C++ port in ~30 seconds
\
\ these times are obviously relative and based on my machine at the time
\ the tests were written, but i wanted consistent tests that could be
\ tracked over time.
	
'BENCH-SIZE "small" make-var

"demo-common" import 
"hashing" import 
"unittest" import
"sorting" import
"numeric" import
"random" import 

\ time & display how long func runs
: timeit ( func -- )
	@locals [ t0 t1 ]
	cpu-time t0!
	func call
	cpu-time t1!
	"     * Ran in" . t1 t0 - 4 2 fmt-float . "seconds" . CR
	;
	
\ nrops = number of operations represented by func
\ what = text description of what is being calculated / second
: timeit-ops ( func nrops what -- )
	@locals [ t0 t1 ]
	cpu-time t0!
	func call
	cpu-time t1!
	"     * Ran in" . t1 t0 - 4 2 fmt-float . "seconds (" .. nrops t1 t0 - / 9 1 fmt-float . what .. "/second)" . CR
	;
	
: benchmark-prime-sieve
	@locals [ PRIMES sval ]	

	BENCH-SIZE
	[
		\ Python = 30 seconds
		[ [ "small" ] { { 60000 prime-sieve drop } 60000 "checked" timeit-ops } ]
		\ Lua = 31 seconds
		[ [ "medium" ] { { 120000 prime-sieve drop } 120000 "checked" timeit-ops } ] 
		\ C++ = 30.4 seconds
		[ [ "large" ] { { 2400000 prime-sieve drop } 2400000 "checked" timeit-ops } ]
		[ else { "Bad value for BENCH-SIZE: " BENCH-SIZE str + error } ]
	] case
	
	\ test a smaller set for correctness
	\ reference/prime-sieve.py used to generate expected values
	10000 prime-sieve PRIMES!
	PRIMES length 1229 expect== \ check # of primes found
	PRIMES -1 get 9973 expect== \ check final value 
	\ convert to space-separated string and calculate hash/checksum
	PRIMES { str } map " " string-join sval!
	
	sval crc32-calc int32-to-hex "d105460e"	expect==
	sval hash-fnv-32 int32-to-hex "d4d75463" expect==
	;

: benchmark-fibonacci-cond 
	"    " .
	BENCH-SIZE
	[
		\ Python = 25 seconds
		[ [ "small" ] { { { ( i ) i gen-ith-fibonacci-cond . } 0 1 22 for-count CR } 22 "numbers" timeit-ops } ]
		\ Lua = 22 seconds
		[ [ "medium" ] { { { ( i ) i gen-ith-fibonacci-cond . } 0 1 23 for-count CR } 23 "numbers" timeit-ops } ]
		\ C++ = 23 seconds
		[ [ "large" ] { { { ( i ) i gen-ith-fibonacci-cond . } 0 1 29 for-count CR } 29 "numbers" timeit-ops	 } ]
		[ else { "Bad BENCH-SIZE: " BENCH-SIZE + error } ]
	] case
	
	\ test correctness (use smaller value that runs quickly)
	7 gen-ith-fibonacci-cond 13 expect==
	;

: benchmark-fibonacci-float-list
	BENCH-SIZE
	[
		\ 1476 reaches the limit of max double value (~1.3e308)

		\ Python = 30 seconds
		[ [ "small" ] { { { 1476 gen-fibonacci-float-list drop } 300 repeat } 1476 300 * "numbers" timeit-ops } ]
		\ Lua = 30 seconds
		[ [ "medium" ] { { { 1476 gen-fibonacci-float-list drop } 600 repeat } 1476 600 * "numbers" timeit-ops } ]
		\ C++ = 33 seconds
		[ [ "large" ] { { { 1476 gen-fibonacci-float-list drop } 18000 repeat } 1476 18000 * "numbers" timeit-ops } ]
		[ else { "Bad BENCH-SIZE: " BENCH-SIZE + error } ]
	] case
	
	\ test correctness (expected value from: https://zeptomath.com/tools/fibonaccinumbers.php?number=100)
	100 gen-fibonacci-float-list -1 get 3.54224848179261915075e20 expect==f
	;
	
: benchmark-fibonacci-if 
	"    " .
	BENCH-SIZE
	[
		\ Python = 30 seconds
		[ [ "small" ] { { { ( i ) i gen-ith-fibonacci-if . } 0 1 26 for-count CR } 26 "numbers" timeit-ops } ]
		\ Lua = 24 seconds
		[ [ "medium" ] { { { ( i ) i gen-ith-fibonacci-if . } 0 1 27 for-count CR } 27 "numbers" timeit-ops } ]
		\ C++ = 30 seconds
		[ [ "large" ] { { { ( i ) i gen-ith-fibonacci-if . } 0 1 34 for-count CR } 34 "numbers" timeit-ops } ]
		[ else { "Bad BENCH-SIZE: " BENCH-SIZE + error } ]
	] case
	
	\ test correctness
	8 gen-ith-fibonacci-if 21 expect==
	;
	
: benchmark-fibonacci-direct
	BENCH-SIZE
	[
		\ 604 = max that be generated before overflow happens

		\ Python = 30 seconds
		[ [ "small" ] { { { 604 gen-fibonacci-direct-list drop } 450 repeat } 604 450 * "numbers" timeit-ops } ]
		\ Lua = 32 seconds
		[ [ "medium" ] { { { 604 gen-fibonacci-direct-list drop } 800 repeat } 604 800 * "numbers" timeit-ops } ]
		\ C++ = 32 seconds
		[ [ "large" ] { { { 604 gen-fibonacci-direct-list drop } 20000 repeat } 604 20000 * "numbers" timeit-ops } ]
		[ else { "Bad BENCH-SIZE: " BENCH-SIZE + error } ]
	] case
	
	\ test correctness (expected value from: https://zeptomath.com/tools/fibonaccinumbers.php?number=500)
	500 gen-fibonacci-direct-list -1 get 1.39423224561697880e104 expect==f
	;
	
: benchmark-quicksort 
	@locals [ vals ]
	[ ] vals!
	\ make a fixed seed so this is repeatable
	"hello world foobar bat" random-seed
	BENCH-SIZE
	[
		\ Python = 30 seconds
		[ [ "small" ] { { vals -100000 100000 randint append! } 17850 repeat } ]
		\ Lua = 32 seconds
		[ [ "medium" ] { { vals -100000 100000 randint append! } 36428 repeat } ]
		\ C++ = 32 seconds
		[ [ "large" ] { { vals -100000 100000 randint append! } 612244 repeat } ]
	] case
	
	\ "LEN VALS:" . vals length . CR
	 
	{ vals { } quicksort drop } vals length "numbers" timeit-ops
	;

: benchmark-mergesort
	@locals [ vals ]
	[ ] vals!
	\ make a fixed seed so this is repeatable
	"hello world foobar bat" random-seed
	BENCH-SIZE
	[
		\ Python = 30 seconds
		[ [ "small" ] { { vals -100000 100000 randint append! } 13157 repeat } ]
		\ Lua = 32 seconds
		[ [ "medium" ] { { vals -100000 100000 randint append! } 25831 repeat } ]
		\ C++ = 29 seconds
		[ [ "large" ] { { vals -100000 100000 randint append! } 397217 repeat } ]
	] case
	
	\ "LEN VALS:" . vals length . CR
	 
	{ vals { } mergesort drop } vals length "numbers" timeit-ops
	;
	
: *generic-benchmark-random ( name nrloops-small nrloops-medium nrloops-large )
	@locals [ nrloops ]
	IF BENCH-SIZE "small" == THEN
		nrloops-small nrloops!
	ELIF BENCH-SIZE "medium" == THEN
		nrloops-medium nrloops!
	ELIF BENCH-SIZE "large" == THEN
		nrloops-large nrloops!
	ELSE
		"Bad BENCH-SIZE: " BENCH-SIZE str + error
	END
	
	\ use a fixed string for repeatability
	name RANDOM-MODULE!
	"the hello world jumped over the foo bar" random-seed
	{ { random-int32 drop } nrloops repeat } nrloops "random ints" timeit-ops
	;

: benchmark-random-xorshift32
	"xorshift32" 225338 401561 7238660 *generic-benchmark-random
	;
	
: benchmark-random-mersenne
	"mersenne" 63411 126182 2664500 *generic-benchmark-random
	;

: benchmark-random-xoshiro128++
	"xoshiro128++" 80881 166320 3802806 *generic-benchmark-random
	;

: benchmark-random-xoshiro128starstar
	"xoshiro128**" 80881 166320 3802806 *generic-benchmark-random
	;

: benchmark-random-worker3
	"worker3" 1200 2400 27000 *generic-benchmark-random
	;
	
: generate-random-text ( len -- text )
	@locals [ charset ]
	"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789" charset!
	"" text!
	WHILE text length len < DO
		text charset 0 charset length randint get + text!
	END
	text
	;
		
: generic-test-hash ( func text repeat-small repeat-medium repeat-large -- )
	@locals [ nr-repeat ]
	IF BENCH-SIZE "small" == THEN
		repeat-small nr-repeat!
	ELIF BENCH-SIZE "medium" == THEN
		repeat-medium nr-repeat!
	ELIF BENCH-SIZE "large" == THEN
		repeat-large nr-repeat!
	ELSE
		"Bad BENCH-SIZE: " BENCH-SIZE str + error
	END
	
	{ { text func call drop } nr-repeat repeat } text length nr-repeat * "chars" timeit-ops 
	;
	
: benchmark-hashing
	@locals [ text ]
	\ setup random generation for repeatability
	"xorshift32" RANDOM-MODULE! \ pick fastest method, don't care about randomness quality here
	"hello world a random string blah blah" random-seed
	"Generating ..." . CR
	10000 generate-random-text text!
	"Done" . CR
	"Adler32 ..." . CR
	{ adler32-calc } text 30 60 1100 generic-test-hash 
	"CRC-32 ..." . CR
	{ crc32-calc } text 26 52 1140 generic-test-hash
	"FNV-32 (verbii) ..." . CR
	{ hash-fnv-32 } text 30 60 1304 generic-test-hash
	\ only run ~ 10 seconds here
	"FNV-32 (native) ..." . CR
	{ fnv-1a-32 } text 8000 16000 600000 generic-test-hash
	;
		
	
\ get all user functions starting with 'benchmark-'
\ ** duplication (with changed prefix) from run-all-tests.verb:get-all-tests **
: get-all-benchmarks
	@locals [ words ]
	.wordlist
	{ 0 10 slice 'benchmark- == } filter
	\ sort so tests run in same order on all platforms
	{ } quicksort
	;

\ run test by name (symbol)
\ ** duplicated (with changes) from run-all-tests.verb:run-test-by-name **
: run-benchmark-by-name ( namesym )
	\ not as detailed on the pass/fail handling as run-all-tests is here
	
	"* " namesym symbol->string 10 -1 slice + " ..." + . CR
	namesym 1 make-list make-lambda call
	;

: run-all-benchmarks
	@locals [ t0 t1 ]
	unittest-init

	get-all-benchmarks
	\ total time should not include any script startup time, etc.,
	\ so measure it here ...
	cpu-time t0!
	{ run-benchmark-by-name } for-each
	cpu-time t1!
	unittest-summary
	"    Total time:" . t1 t0 - 4 2 fmt-float . "seconds" . CR
	;
	
: run-one-benchmark ( namestring )
	@locals [ t0 t1 ]
	unittest-init

	\ total time should not include any script startup time, etc.,
	\ so measure it here ...
	cpu-time t0!
	'benchmark- namestring string->symbol + run-benchmark-by-name
	cpu-time t1!
	unittest-summary
	"    Total time:" . t1 t0 - . "seconds" . CR
	;
	
: show-usage
	"Usage: verbii benchmark.verb -- [small|medium|large]" . CR 
	"       verbii benchmark.verb -- [small|medium|large] testname" . CR
	;
	
SCRIPT-ARGS length 
[
	[ [ 0 ] { show-usage } ]
	[ [ 1 2 ] {
			SCRIPT-ARGS 0 get BENCH-SIZE!
			SCRIPT-ARGS 1 get void? if >>run-all
			\ run just the specified test
			SCRIPT-ARGS 1 get run-one-benchmark
			return
			@run-all
			run-all-benchmarks
			} ]
	[ else { show-usage } ]
] case
